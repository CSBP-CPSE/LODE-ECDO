{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing.ipynb\n",
    "\n",
    "## Overview\n",
    "This notebook is for cleaning and other data preprocessing of all the datasets in `/home/jovyan/ODBiz/1-PreProcessing/raw`\n",
    "\n",
    "This notebook includes cells that do the following:\n",
    "- Converts .shp files to .csv files\n",
    "- Extracts lat/lon coordinates from cells that recorded them as JSON strings. Seems like the only dataset this applies to is `BC_Vancouver_Business_Licences.csv`\n",
    "- Fixes `Indigenous_Business_Directory.csv`, which contained commas inside their cells\n",
    "- Removes leading and trailing whitespaces from `NT_Yellowknife_Business_Directory.csv` and also fixes it's weirdly formatted phone numbers\n",
    "- Standardizes dates for the `date_established` variables\n",
    "- Moves processed datasets into the `2-OpenTabulate` folder\n",
    "\n",
    "## External custom scripts\n",
    "A few cells run external scripts have been written as .py files. Here's a list of links to those scripts:\n",
    "- [process_shp_files.py](https://kubeflow.aaw.cloud.statcan.ca/notebook/deil-lode/odbiz-processing/doc/tree/ODBiz/1-PreProcessing/process_shp_files.py): Converts .shp files to .csv files\n",
    "- [standardize_dates.py](https://kubeflow.aaw.cloud.statcan.ca/notebook/deil-lode/odbiz-processing/doc/tree/ODBiz/1-PreProcessing/standardize_dates.py): Standardizes dates for the `date_established` variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-22T19:58:08.362443Z",
     "iopub.status.busy": "2022-06-22T19:58:08.362183Z",
     "iopub.status.idle": "2022-06-22T19:58:09.318204Z",
     "shell.execute_reply": "2022-06-22T19:58:09.317525Z",
     "shell.execute_reply.started": "2022-06-22T19:58:08.362416Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T22:34:07.979627Z",
     "iopub.status.busy": "2022-05-19T22:34:07.979352Z",
     "iopub.status.idle": "2022-05-19T22:34:08.818584Z",
     "shell.execute_reply": "2022-05-19T22:34:08.817590Z",
     "shell.execute_reply.started": "2022-05-19T22:34:07.979601Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First bring all raw files into processed. \n",
    "# We do this because more files won't need any cleaning work, so this is quicker than moving them manually. \n",
    "# Any files that require processing work will simply replace the raw files in the processed folder later\n",
    "\n",
    "src = '../1-PreProcessing/raw'\n",
    "dst = '../1-PreProcessing/processed'\n",
    "\n",
    "if os.path.exists(dst):\n",
    "    shutil.rmtree(dst)\n",
    "    shutil.copytree(src, dst)\n",
    "    \n",
    "files_in_directory = os.listdir(dst)\n",
    "filtered_files = [file for file in files_in_directory if not file.endswith(\".csv\")]\n",
    "for file in filtered_files:\n",
    "    try:\n",
    "        path_to_file = os.path.join(dst, file)\n",
    "        os.remove(path_to_file)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T22:34:11.877709Z",
     "iopub.status.busy": "2022-05-19T22:34:11.877455Z",
     "iopub.status.idle": "2022-05-19T22:34:31.491598Z",
     "shell.execute_reply": "2022-05-19T22:34:31.490762Z",
     "shell.execute_reply.started": "2022-05-19T22:34:11.877683Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shapefile processing has been replaced with process_shp_files.py \n",
    "# This script includes Port Moody!\n",
    "import process_shp_files\n",
    "process_shp_files.main()\n",
    "\n",
    "# # All shapefiles (except Port Moody)\n",
    "\n",
    "# import os\n",
    "# for root, dirs, files in os.walk(\"../1-PreProcessing/raw/shapefiles\"):\n",
    "#     for file in files:\n",
    "#         if file.endswith(\".shp\"):\n",
    "#             try:\n",
    "#                 head, tail = os.path.split(os.path.join(root, file))\n",
    "#                 head = head.replace('shapefile', '')\n",
    "#                 head = head.replace(\"/home/jovyan/ODBiz/1-PreProcessing/raw/shapefiles/\", '')\n",
    "#                 head = head.replace(\"/\", '')          \n",
    "#                 tail = tail.replace('.shp', '')\n",
    "#                 name = head + tail\n",
    "#                 print(name)\n",
    "\n",
    "#                 fp = (os.path.join(root, file))\n",
    "#                 city = gpd.read_file(fp)\n",
    "#                 print(city.crs)\n",
    "#                 city = city.to_crs(epsg=4326)\n",
    "#                 print(city.crs)\n",
    "#                 sub_city = city.head(500)\n",
    "#                 city['lon'] = city.geometry.x\n",
    "#                 city['lat'] = city.geometry.y\n",
    "\n",
    "#                 city.to_csv(\"../1-PreProcessing/raw/\"+name+\".csv\")\n",
    "#                 city.to_csv(\"../1-PreProcessing/processed/\"+name+\".csv\")\n",
    "\n",
    "#             except:\n",
    "#                 print('error with file above')\n",
    "#                 pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T22:34:31.493089Z",
     "iopub.status.busy": "2022-05-19T22:34:31.492881Z",
     "iopub.status.idle": "2022-05-19T22:34:32.295234Z",
     "shell.execute_reply": "2022-05-19T22:34:32.294498Z",
     "shell.execute_reply.started": "2022-05-19T22:34:31.493065Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # BC Port Moody Shapefile\n",
    "\n",
    "# fp = \"../1-PreProcessing/raw/shapefiles/BC_Port_Moody_shapefile/Business_Directory.shp\"\n",
    "# name = \"port moody\"\n",
    "\n",
    "# city = gpd.read_file(fp)\n",
    "\n",
    "# print(city.crs)\n",
    "# city = city.to_crs(epsg=4326)\n",
    "# print(city.crs)\n",
    "\n",
    "# sub_city = city.head(500)\n",
    "\n",
    "# city['lon'] = city.centroid.x\n",
    "# city['lat'] = city.centroid.y\n",
    "\n",
    "# #print(city.head)\n",
    "\n",
    "# city.to_csv(\"../1-PreProcessing/raw/BC_Port_Moody_Business_Directory.csv\")\n",
    "# city.to_csv(\"../1-PreProcessing/processed/BC_Port_Moody_Business_Directory.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T22:34:34.026681Z",
     "iopub.status.busy": "2022-05-19T22:34:34.026411Z",
     "iopub.status.idle": "2022-05-19T22:34:46.125761Z",
     "shell.execute_reply": "2022-05-19T22:34:46.124800Z",
     "shell.execute_reply.started": "2022-05-19T22:34:34.026653Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BC vancouver lat/long\n",
    "\n",
    "df = pd.read_csv('../1-PreProcessing/raw/BC_Vancouver_Business_Licences.csv')\n",
    "\n",
    "def strip_point(x):   \n",
    "    try:\n",
    "        t = x.strip(r'{\"\"coordinates\"\": [')\n",
    "        t = t.rstrip('], \"\"type\"\": \"\"Point\"\"}')\n",
    "        t = t.replace(',', '')\n",
    "        return t.split()\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "LONGS=[]\n",
    "LATS=[]\n",
    "for i in df[\"Geom\"]:\n",
    "    try:\n",
    "        LONGS.append(strip_point(i)[0])\n",
    "        LATS.append(strip_point(i)[1])\n",
    "    except:\n",
    "        LONGS.append(np.nan)\n",
    "        LATS.append(np.nan)\n",
    "\n",
    "df[\"long\"]=LONGS\n",
    "df[\"lat\"]=LATS\n",
    "\n",
    "df.to_csv('../1-PreProcessing/processed/BC_Vancouver_Business_Licences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T22:34:46.127390Z",
     "iopub.status.busy": "2022-05-19T22:34:46.127184Z",
     "iopub.status.idle": "2022-05-19T22:34:46.350796Z",
     "shell.execute_reply": "2022-05-19T22:34:46.350116Z",
     "shell.execute_reply.started": "2022-05-19T22:34:46.127365Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NT Yellowknife whitespaces and phone numbers\n",
    "\n",
    "df = pd.read_csv('../1-PreProcessing/raw/NT_Yellowknife_Business_Directory.csv')\n",
    "\n",
    "cols = ['BUSINESSNAME', 'MUNICIPAL ADDRESS3', 'BUSINESSTYPE', 'PHONE', 'EMAILADDRESS']\n",
    "df[cols] = df[cols].apply(lambda x: x.str.strip())\n",
    "\n",
    "df['PHONE'] = df['PHONE'].str.extract(r'(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})')\n",
    "\n",
    "df.to_csv('../1-PreProcessing/processed/NT_Yellowknife_Business_Directory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T22:34:46.352182Z",
     "iopub.status.busy": "2022-05-19T22:34:46.351998Z",
     "iopub.status.idle": "2022-05-19T22:34:46.486451Z",
     "shell.execute_reply": "2022-05-19T22:34:46.485691Z",
     "shell.execute_reply.started": "2022-05-19T22:34:46.352158Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix the cells with commas in them in the Indigenous_Business_Directory.csv file\n",
    "\n",
    "import csv\n",
    "\n",
    "# Define csv file path\n",
    "in_file = '../1-PreProcessing/raw/Indigenous_Business_Directory.csv'\n",
    "out_file = '../1-PreProcessing/processed/Indigenous_Business_Directory.csv'\n",
    "\n",
    "# Initialize a list that will be our new corrected csv\n",
    "newcsv = []\n",
    "\n",
    "# Open a read only copy of the csv file\n",
    "with open(in_file, mode = 'r', newline='', encoding='utf8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "\n",
    "    # For each row in the csv...\n",
    "    i = 0\n",
    "    for row in csvreader:\n",
    "\n",
    "        # For each cell in each row...\n",
    "        j = 0\n",
    "        for val in row:\n",
    "\n",
    "            # If the known anomoly is found...\n",
    "            if '$25' in val:\n",
    "\n",
    "                # Then perform the fixing operation\n",
    "                newval = ','.join(row[j:j+3])   # Concat the 3 cells that make up the sentence\n",
    "                del row[j:j+3]                  # Delete the 3 cells from the list\n",
    "                row.insert(j, newval)           # Insert the concat'd value back into the list\n",
    "            j += 1\n",
    "\n",
    "        # Append the row to the newcsv file\n",
    "        newcsv.append(row)\n",
    "\n",
    "        # Delete the unnecessary 19th column\n",
    "        row_len = len(row)\n",
    "        if row_len == 19:\n",
    "\n",
    "            # Give a warning message if non-empty values are deleted\n",
    "            if row[-1] != '':\n",
    "                print('WARNING, DELETED VALUE:', row[-1])\n",
    "\n",
    "            # Delete extra column\n",
    "            del row[-1]\n",
    "\n",
    "        # Add extra commas if they're missing\n",
    "        row_len = len(row)\n",
    "        print(i,':', row_len)\n",
    "        while(len(row) < 18):\n",
    "            row.append('')\n",
    "\n",
    "        i += 1\n",
    "\n",
    "# Delete the first row\n",
    "del newcsv[0]\n",
    "\n",
    "# Delete that one empty row after the header row\n",
    "del newcsv[1]\n",
    "\n",
    "# Save newcsv to a .csv file\n",
    "with open(out_file, mode = 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    print(f'Saving the newcsv to {out_file} ...')\n",
    "    writer.writerows(newcsv)\n",
    "print(f'Saved newcsv to {out_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the dates of the csvs with non-empty date_established fields using standardize_dates.py\n",
    "import standardize_dates\n",
    "standardize_dates.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-22T19:58:11.891235Z",
     "iopub.status.busy": "2022-06-22T19:58:11.890957Z",
     "iopub.status.idle": "2022-06-22T19:58:13.634760Z",
     "shell.execute_reply": "2022-06-22T19:58:13.634011Z",
     "shell.execute_reply.started": "2022-06-22T19:58:11.891205Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transfer files directly from PreProcessing/processed to opentabulate/data/input\n",
    "src = '../1-PreProcessing/processed'\n",
    "dst = '../2-OpenTabulate/data/input'\n",
    "\n",
    "if os.path.exists(dst):\n",
    "    shutil.rmtree(dst)\n",
    "    shutil.copytree(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-13T16:23:26.970934Z",
     "iopub.status.busy": "2022-04-13T16:23:26.970602Z",
     "iopub.status.idle": "2022-04-13T16:23:26.978405Z",
     "shell.execute_reply": "2022-04-13T16:23:26.977479Z",
     "shell.execute_reply.started": "2022-04-13T16:23:26.970904Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List the number of files(/folders?) in each directory listed below\n",
    "raw = '../1-PreProcessing/raw'\n",
    "pro = '../1-PreProcessing/processed'\n",
    "input_ = '../2-OpenTabulate/data/input'\n",
    "output_ = '../2-OpenTabulate/data/output'\n",
    "print(len(os.listdir(raw)))\n",
    "print(len(os.listdir(pro)))\n",
    "print(len(os.listdir(input_)))\n",
    "print(len(os.listdir(output_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-23T18:37:15.511077Z",
     "iopub.status.busy": "2022-08-23T18:37:15.510764Z",
     "iopub.status.idle": "2022-08-23T18:37:15.515582Z",
     "shell.execute_reply": "2022-08-23T18:37:15.514613Z",
     "shell.execute_reply.started": "2022-08-23T18:37:15.511044Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEMPORARY install packages probably in a not good way\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install thefuzz\n",
    "# !{sys.executable} -m pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T18:09:53.550273Z",
     "iopub.status.busy": "2022-09-02T18:09:53.550032Z",
     "iopub.status.idle": "2022-09-02T18:09:54.140376Z",
     "shell.execute_reply": "2022-09-02T18:09:54.139663Z",
     "shell.execute_reply.started": "2022-09-02T18:09:53.550205Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/thefuzz/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# This finds address matches between files by looking for exact matches on street number and 'fuzzy' matches on street name\n",
    "# the goal is to use Open Addresses files to assign geocoordinates\n",
    "\n",
    "# I want to start by trying out the script on a sample. \n",
    "# download ODA data for Alberta.\n",
    "\n",
    "# let's try matching even for those with geocodes\n",
    "# then the results can be compared\n",
    "\n",
    "# conda install thefuzz\n",
    "# conda install unidecode\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "import time\n",
    "import sys\n",
    "import unidecode #to remove accents\n",
    "import re\n",
    "from AddressFuncs import DirectionCheck, NameIsNumber\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T18:10:01.728516Z",
     "iopub.status.busy": "2022-09-02T18:10:01.728224Z",
     "iopub.status.idle": "2022-09-02T18:10:01.732995Z",
     "shell.execute_reply": "2022-09-02T18:10:01.732252Z",
     "shell.execute_reply.started": "2022-09-02T18:10:01.728481Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input_dir='inputs/'\n",
    "# output_dir='outputs/'\n",
    "\n",
    "# inputs \n",
    "# formatted_on_test.csv\n",
    "# ODA_MB_v1.csv\n",
    "\n",
    "# database=sys.argv[1]\n",
    "# addresses=sys.argv[2]\n",
    "# output=sys.argv[3]\n",
    "\n",
    "# t1=time.time()\n",
    "\n",
    "\n",
    "#This is a semi-arbitrary cut off for fuzzy string matching\n",
    "cut_off = 80\n",
    "#Read input files\n",
    "\n",
    "# loop through and do seperately for each province \n",
    "# let's test it on one province again first. AB\n",
    "\n",
    "\n",
    "provinces = ['AB', 'BC', 'MB', 'NB', 'NT', 'NS', 'ON', 'PE', 'QC', 'SK']\n",
    "# provinces = ['AB', 'BC', 'MB', 'NB', 'NT', 'NS', 'PE', 'QC', 'SK']\n",
    "# provinces = ['SK']\n",
    "# provinces = ['AB', 'BC', 'MB', 'QC']\n",
    "\n",
    "sample_size_set = 1000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-02T18:10:05.793742Z",
     "iopub.status.busy": "2022-09-02T18:10:05.793482Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB\n",
      "rows to match:  62804\n",
      "ODA addresses: 1776750\n"
     ]
    }
   ],
   "source": [
    "# for province_code in provinces:\n",
    "#     file_location = \"https://www150.statcan.gc.ca/n1/pub/46-26-0001/2021001/ODA_\" + province_code + \"_v1.zip\"\n",
    "\n",
    "# for each province, subset the correct bit of formatted for df\n",
    "# get the correct file for DF\n",
    "# save it to a unique file name\n",
    "\n",
    "# SAM TO ADD \n",
    "# (1) some way to check for the city - there might be lots of main streets.\n",
    "# (2) set a higher cutoff for streets with a number in them, probably 90\n",
    "# like 17th av (since it matches closely with 16th av)\n",
    "\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "\n",
    "for province_code in provinces:\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    print(province_code)\n",
    "\n",
    "    # df=pd.read_csv(input_dir+database)\n",
    "    df = pd.read_csv('data/formatted.csv', low_memory=False)\n",
    "\n",
    "    # test \n",
    "    df = df[df['province'] == province_code]\n",
    "\n",
    "    # drop any entries without a street number\n",
    "    df = df.dropna(subset=['street_no'])\n",
    "    \n",
    "    print('rows to match: ', len(df))\n",
    "\n",
    "    #read in openadress file\n",
    "    # DF=pd.read_csv(input_dir+addresses)\n",
    "    \n",
    "    \n",
    "    if (province_code == 'QC'):\n",
    "        ocd_file = \"data/oda-addresses/ODA_\" + province_code + \"_v1_formatted.csv\"\n",
    "    else:\n",
    "        ocd_file = \"data/oda-addresses/ODA_\" + province_code + \"_v1.csv\"\n",
    "\n",
    "    DF=pd.read_csv(ocd_file, low_memory=False)\n",
    "    #drop any entries without a street number\n",
    "    DF=DF.dropna(subset=['street_no'])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    #force street numbers to be integers then strings (pandas converts to float if there are empty entries)\n",
    "    DF[\"street_no\"] = DF[\"street_no\"].astype('int', errors='ignore').astype('str')\n",
    "    df[\"street_no\"] = pd.to_numeric(df[\"street_no\"], errors='coerce').fillna(0).astype(np.int64)\n",
    "    df[\"street_no\"] = df[\"street_no\"].astype('int', errors='ignore').astype('str')\n",
    "\n",
    "\n",
    "    # FOR TESTING, remove duplicates\n",
    "    \n",
    "\n",
    "    d1 = len(df)\n",
    "    \n",
    "    # we now do deduplication in another stage\n",
    "#     if (province_code == 'QC'):\n",
    "#         df = df.drop_duplicates(subset=['street_no','formatted_fr'])\n",
    "#     else:\n",
    "#         df = df.drop_duplicates(subset=['street_no','formatted_en'])\n",
    "    \n",
    "    d2 = len(df)\n",
    "    \n",
    "#     print('rows after deduplication: ', d2)\n",
    "    ######\n",
    "    \n",
    "    print('ODA addresses:', len(DF))\n",
    "    \n",
    "    # FOR TESTING take a sample\n",
    "#     sample_size = len(df)\n",
    "    \n",
    "    sample_size = sample_size_set\n",
    "    if (len(df) > sample_size):\n",
    "        df = df.sample(sample_size)\n",
    "    else:\n",
    "        sample_size = len(df)\n",
    "\n",
    "    num = list(df[\"street_no\"])\n",
    "    street = []\n",
    "    \n",
    "    \n",
    "    #remove accents from input dataframe\n",
    "    \n",
    "    if (province_code == 'QC'):\n",
    "        for i in df.formatted_fr.astype('str'):\n",
    "            street.append(unidecode.unidecode(i))\n",
    "    else:\n",
    "        for i in df.formatted_en.astype('str'):\n",
    "            street.append(unidecode.unidecode(i))\n",
    "    \n",
    "\n",
    "    n = len(num)\n",
    "    \n",
    "    # create empty columns that will be added from oda to new dataset\n",
    "    MATCHES_r = [0]*n\n",
    "\n",
    "    ratio = [0]*n\n",
    "\n",
    "    x = [0]*n\n",
    "    y = [0]*n\n",
    "    \n",
    "    csdname_oda = [0]*n\n",
    "    provider_oda = [0]*n\n",
    "    city_pcs_oda = [0]*n\n",
    "\n",
    "\n",
    "\n",
    "    #loop through main list\n",
    "    for i in range(n):\n",
    "        number = num[i]\n",
    "        \n",
    "#         print('street number: ', number)\n",
    "\n",
    "        #restrict to only consider entries with a matching street number\n",
    "        \n",
    "        # SAM EDIT try instead to find near matches for street number? within one or two\n",
    "        # is that acceptable accuracy?\n",
    "        DF_temp = DF.loc[DF[\"street_no\"] == number]\n",
    "        \n",
    "#         print(len(DF_temp))\n",
    "\n",
    "        #remove accents from address database, and restrict to unique names (avoid repetitions)\n",
    "        STREET=[]\n",
    "        \n",
    "        \n",
    "        for j in DF_temp[\"street\"].unique().astype('str'):\n",
    "            STREET.append(unidecode.unidecode(j))\t\n",
    "\n",
    "            \n",
    "\n",
    "        #process reduced address list with fuzzywuzzy\n",
    "\n",
    "\n",
    "        addr1 = street[i]\n",
    "#         print('search: ', addr1)\n",
    "        if STREET==[]: #this means the street number isn't in the address list, so obviously no match\n",
    "            #do nothing\n",
    "            r=0\n",
    "            best=''\n",
    "        else:\t\t\n",
    "            bests = process.extract(addr1, STREET, scorer=fuzz.ratio)\n",
    "    # \t\tprint(bests)\n",
    "            #The print statement below is to determine how much 'better' the best match is than the 2nd best\n",
    "    #\t\tif len(bests)>1:\t\n",
    "    #\t\t\tprint((bests[0])[1]-(bests[1])[1])\n",
    "\n",
    "            #bests is a list of tuples, of the form (\"street name\", ratio) \n",
    "            b0 = bests[0]\n",
    "\n",
    "            r = b0[1]\n",
    "            best = b0[0]\n",
    "            ratio[i] = r\n",
    "            MATCHES_r[i] = best\n",
    "        #This is where we determine if we found an address match\n",
    "        #We consider a match if the 'best' match is significantly better than the 2nd best, AND that the best is also good (>70, semi-arbitrary cut-off).\n",
    "            #assume directions match until we find they don't\n",
    "            DIR_MATCH = True\n",
    "            RAT_MATCH = False\n",
    "            if r > cut_off:\n",
    "                if r == 100: #perfect string match\n",
    "                    RAT_MATCH = True\n",
    "                else:\n",
    "                    check_list = pd.Series([addr1,best])\t\t\t\t\t\t\n",
    "                    #check to see if direction exists and matches\n",
    "                    DIR_MATCH = DirectionCheck(check_list)\n",
    "                    #check to see if the street name is a number and that if so it isn't a mismatch\n",
    "                    NUM_MATCH = NameIsNumber(check_list)\n",
    "                    if (DIR_MATCH == True) and (NUM_MATCH == True):\n",
    "                        if len(bests) > 1:\n",
    "                            r1 = (bests[1])[1]\n",
    "#                             print('second best: ', (bests[1])[0])\n",
    "                            if (r-r1) > 10: #clearly better than 2nd option\n",
    "                                RAT_MATCH = True\n",
    "\n",
    "\n",
    "                            else: #not clearly better than second option\n",
    "                                RAT_MATCH = False\n",
    "\n",
    "\n",
    "                        else: #Only one option, and score above 70\n",
    "                            RAT_MATCH=True\n",
    "                    else:\n",
    "                        RAT_MATCH =False\n",
    "            else: #Best option ratio <cutoff, not good\n",
    "                RAT_MATCH=False\n",
    "\n",
    "\n",
    "            if RAT_MATCH==True:\n",
    "                    #some addresses repeat in address lists with slightly different lat/lons\n",
    "                    #this is PERPLEXING. We take the mean.\n",
    "                    x[i]=DF_temp.loc[DF_temp[\"street\"]==best,\"longitude\"].mean()\n",
    "                    y[i]=DF_temp.loc[DF_temp[\"street\"]==best,\"latitude\"].mean()\n",
    "                    \n",
    "#                     print(i, ': ', DF_temp.loc[DF_temp[\"street\"]==best,\"provider\"].values[0])\n",
    "                    \n",
    "                    if not DF_temp.loc[DF_temp[\"street\"]==best,\"csdname\"].empty:\n",
    "                        csdname_oda[i] = DF_temp.loc[DF_temp[\"street\"]==best,\"csdname\"].values[0]\n",
    "#                     provider_oda[i] = DF_temp.loc[DF_temp[\"street\"]==best,\"provider\"].values[0]\n",
    "#                     city_pcs_oda[i] = DF_temp.loc[DF_temp[\"street\"]==best,\"city_pcs\"].values[0]\n",
    "                    else:\n",
    "                        csdname_oda[i] = ''\n",
    "            else:\n",
    "                    x[i]=''\n",
    "                    y[i]=''\n",
    "                    csdname_oda[i] = ''\n",
    "#                     csdname_oda[i] = ''\n",
    "#                     provider_oda[i] = ''\n",
    "#                     city_pcs_oda[i] = ''\n",
    "#         print('match: ', best)\n",
    "#         print('score: ', r)\n",
    "    df[\"matches_r\"]=MATCHES_r\t\n",
    "    df[\"ratio\"]=ratio\n",
    "\n",
    "\n",
    "    df[\"x\"]=x\n",
    "    df[\"y\"]=y\n",
    "    \n",
    "    df[\"csdname_oda\"] = csdname_oda\n",
    "#     df[\"provider_oda\"] = provider_oda\n",
    "#     df['city_pcs_oda'] = city_pcs_oda\n",
    "\n",
    "    #create output\n",
    "    # for testing, we don't need all the columns - just the address, and maybe the name\n",
    "#     cols = list(df)\n",
    "    # df_out = df[[cols[0],'street_no','street_name','matches_r','ratio','x','y']]\n",
    "    \n",
    "    no_matches = df['ratio'][df['ratio'] > cut_off].count()\n",
    "    percent_matches = (100 * no_matches / sample_size)\n",
    "    print('matches (n = ', sample_size, ', r = ', cut_off, '): ', percent_matches, '%')\n",
    "    \n",
    "    output_filename = 'output-' + province_code + '.csv'\n",
    "    df.to_csv(output_filename, index=False)\n",
    "\n",
    "    t2 = time.time()\n",
    "    print('time taken: ', str(round(t2-t1, 2)), '\\n')\n",
    "    \n",
    "#     df_all = df_all.append(df)\n",
    "    df_all = pd.concat([df_all, df])\n",
    "\n",
    "    \n",
    "\n",
    "# df_all.to_csv(\"output_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-16T14:53:26.880095Z",
     "iopub.status.busy": "2022-08-16T14:53:26.878963Z",
     "iopub.status.idle": "2022-08-16T14:53:26.888025Z",
     "shell.execute_reply": "2022-08-16T14:53:26.887162Z",
     "shell.execute_reply.started": "2022-08-16T14:53:26.880056Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each province print\n",
    "# size of dataframe\n",
    "# how many were not geocoded\n",
    "# number of oda addresses\n",
    "# how many with matches found\n",
    "# how long did it take to compute\n",
    "    # if ages, then message every batch of 100\n",
    "    \n",
    "df_all.to_csv(\"output_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-01T14:14:24.039509Z",
     "iopub.status.busy": "2022-09-01T14:14:24.039248Z",
     "iopub.status.idle": "2022-09-01T14:14:24.050227Z",
     "shell.execute_reply": "2022-09-01T14:14:24.049144Z",
     "shell.execute_reply.started": "2022-09-01T14:14:24.039480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['street_name'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-16T18:47:59.589391Z",
     "iopub.status.busy": "2022-08-16T18:47:59.588959Z",
     "iopub.status.idle": "2022-08-16T18:48:01.322686Z",
     "shell.execute_reply": "2022-08-16T18:48:01.321779Z",
     "shell.execute_reply.started": "2022-08-16T18:47:59.589304Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This finds address matches between files by looking for exact matches on street number and 'fuzzy' matches on street name\n",
    "# the goal is to use Open Addresses files to assign geocoordinates\n",
    "\n",
    "# I want to start by trying out the script on a sample. \n",
    "# download ODA data for Alberta.\n",
    "\n",
    "# conda install thefuzz\n",
    "# conda install unidecode\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "import time\n",
    "import sys\n",
    "import unidecode #to remove accents\n",
    "import re\n",
    "from AddressFuncs import DirectionCheck, NameIsNumber\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-16T18:48:04.472534Z",
     "iopub.status.busy": "2022-08-16T18:48:04.471391Z",
     "iopub.status.idle": "2022-08-16T18:48:04.477936Z",
     "shell.execute_reply": "2022-08-16T18:48:04.476981Z",
     "shell.execute_reply.started": "2022-08-16T18:48:04.472491Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input_dir='inputs/'\n",
    "# output_dir='outputs/'\n",
    "\n",
    "# inputs \n",
    "# formatted_on_test.csv\n",
    "# ODA_MB_v1.csv\n",
    "\n",
    "# database=sys.argv[1]\n",
    "# addresses=sys.argv[2]\n",
    "# output=sys.argv[3]\n",
    "\n",
    "# t1=time.time()\n",
    "\n",
    "\n",
    "#This is a semi-arbitrary cut off for fuzzy string matching\n",
    "cut_off=70\n",
    "#Read input files\n",
    "\n",
    "# loop through and do seperately for each province \n",
    "# let's test it on one province again first. AB\n",
    "\n",
    "\n",
    "provinces = ['AB', 'BC', 'MB', 'NB', 'NT', 'NS', 'ON', 'PE', 'QC', 'SK']\n",
    "provinces = ['AB', 'BC', 'MB', 'NB', 'NT', 'NS', 'PE', 'QC', 'SK']\n",
    "# provinces = ['AB', 'BC', 'MB']\n",
    "\n",
    "sample_size = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-16T18:48:06.415694Z",
     "iopub.status.busy": "2022-08-16T18:48:06.415101Z",
     "iopub.status.idle": "2022-08-16T18:49:37.471743Z",
     "shell.execute_reply": "2022-08-16T18:49:37.470714Z",
     "shell.execute_reply.started": "2022-08-16T18:48:06.415660Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB\n",
      "rows:  599\n",
      "rows after deduplication:  243\n",
      "ODA addresses: 1776750\n",
      "percent matches (from sample n = 200):  196\n",
      "time taken:  37.01 \n",
      "\n",
      "BC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22039/2910145675.py:186: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_all.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows:  129789\n",
      "rows after deduplication:  57953\n",
      "ODA addresses: 796178\n",
      "percent matches (from sample n = 200):  81\n",
      "time taken:  15.81 \n",
      "\n",
      "MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22039/2910145675.py:186: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_all.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows:  3\n",
      "rows after deduplication:  3\n",
      "ODA addresses: 236847\n",
      "percent matches (from sample n = 200):  0\n",
      "time taken:  1.56 \n",
      "\n",
      "NB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22039/2910145675.py:186: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_all.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows:  0\n",
      "rows after deduplication:  0\n",
      "ODA addresses: 406040\n",
      "percent matches (from sample n = 200):  0\n",
      "time taken:  4.15 \n",
      "\n",
      "NT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22039/2910145675.py:186: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_all.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows:  1352\n",
      "rows after deduplication:  851\n",
      "ODA addresses: 6996\n",
      "percent matches (from sample n = 200):  192\n",
      "time taken:  0.8 \n",
      "\n",
      "NS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22039/2910145675.py:186: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_all.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows:  0\n",
      "rows after deduplication:  0\n",
      "ODA addresses: 883501\n",
      "percent matches (from sample n = 200):  0\n",
      "time taken:  6.63 \n",
      "\n",
      "PE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22039/2910145675.py:186: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_all.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows:  0\n",
      "rows after deduplication:  0\n",
      "ODA addresses: 74412\n",
      "percent matches (from sample n = 200):  0\n",
      "time taken:  0.74 \n",
      "\n",
      "QC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22039/2910145675.py:186: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_all.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows:  5003\n",
      "rows after deduplication:  3571\n",
      "ODA addresses: 1254235\n",
      "percent matches (from sample n = 200):  1\n",
      "time taken:  23.13 \n",
      "\n",
      "SK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22039/2910145675.py:186: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_all.append(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows:  1\n",
      "rows after deduplication:  1\n",
      "ODA addresses: 157710\n",
      "percent matches (from sample n = 200):  0\n",
      "time taken:  1.18 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22039/2910145675.py:186: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_all = df_all.append(df)\n"
     ]
    }
   ],
   "source": [
    "# for province_code in provinces:\n",
    "#     file_location = \"https://www150.statcan.gc.ca/n1/pub/46-26-0001/2021001/ODA_\" + province_code + \"_v1.zip\"\n",
    "\n",
    "# for each province, subset the correct bit of formatted for df\n",
    "# get the correct file for DF\n",
    "# save it to a unique file name\n",
    "\n",
    "df_all = pd. DataFrame()\n",
    "\n",
    "for province_code in provinces:\n",
    "    \n",
    "    t1=time.time()\n",
    "    \n",
    "    print(province_code)\n",
    "\n",
    "    # df=pd.read_csv(input_dir+database)\n",
    "    df = pd.read_csv('formatted.csv', low_memory=False)\n",
    "\n",
    "    # test \n",
    "    df = df[df['province'] == province_code]\n",
    "\n",
    "    # drop any entries without a street number\n",
    "    df = df.dropna(subset=['street_no'])\n",
    "    \n",
    "    print('rows: ', len(df))\n",
    "\n",
    "    #read in openadress file\n",
    "    # DF=pd.read_csv(input_dir+addresses)\n",
    "    \n",
    "    ocd_file = \"data/oda-addresses/ODA_\" + province_code + \"_v1.csv\"\n",
    "\n",
    "    DF=pd.read_csv(ocd_file, low_memory=False)\n",
    "    #drop any entries without a street number\n",
    "    DF=DF.dropna(subset=['street_no'])\n",
    "    \n",
    "    \n",
    "\n",
    "    # SAM need to adjust to use formatted street names\n",
    "    # formatted_en\n",
    "\n",
    "    #force street numbers to be integers then strings (pandas converts to float if there are empty entries)\n",
    "    df[\"street_no\"] = df[\"street_no\"].astype('int', errors='ignore').astype('str')\n",
    "    DF[\"street_no\"] = DF[\"street_no\"].astype('int', errors='ignore').astype('str')\n",
    "\n",
    "    # FOR TESTING, remove duplicates\n",
    "\n",
    "    d1 = len(df)\n",
    "    df = df.drop_duplicates(subset=['street_no','formatted_en'])\n",
    "    d2 = len(df)\n",
    "    \n",
    "    print('rows after deduplication: ', d2)\n",
    "    ######\n",
    "    \n",
    "    print('ODA addresses:', len(DF))\n",
    "    \n",
    "    # FOR TESTING take a sample\n",
    "    \n",
    "    \n",
    "    if (len(df) > sample_size):\n",
    "        df = df.sample(sample_size)\n",
    "\n",
    "\n",
    "    num=list(df[\"street_no\"])\n",
    "    street=[]\n",
    "    \n",
    "    \n",
    "    #remove accents from input dataframe\n",
    "    \n",
    "    if (province_code == 'QC'):\n",
    "        for i in df.formatted_fr.astype('str'):\n",
    "            street.append(unidecode.unidecode(i))\n",
    "    else:\n",
    "        for i in df.formatted_en.astype('str'):\n",
    "            street.append(unidecode.unidecode(i))\n",
    "    \n",
    "\n",
    "    n=len(num)\n",
    "    MATCHES_r=[0]*n\n",
    "\n",
    "    ratio=[0]*n\n",
    "\n",
    "    x=[0]*n\n",
    "    y=[0]*n\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #loop through main list\n",
    "    for i in range(n):\n",
    "        number=num[i]\n",
    "\n",
    "        #restrict to only consider entries with a matching street number\n",
    "        DF_temp=DF.loc[DF[\"street_no\"]==number]\n",
    "\n",
    "        #remove accents from address database, and restrict to unique names (avoid repetitions)\n",
    "        STREET=[]\n",
    "        for j in DF_temp[\"street\"].unique().astype('str'):\n",
    "            STREET.append(unidecode.unidecode(j))\t\n",
    "\n",
    "\n",
    "\n",
    "        #process reduced address list with fuzzywuzzy\n",
    "\n",
    "\n",
    "        addr1=street[i]\n",
    "        if STREET==[]: #this means the street number isn't in the address list, so obviously no match\n",
    "            #do nothing\n",
    "            r=0\n",
    "            best=''\n",
    "        else:\t\t\n",
    "            bests=process.extract(addr1,STREET,scorer=fuzz.ratio)\n",
    "    # \t\tprint(bests)\n",
    "            #The print statement below is to determine how much 'better' the best match is than the 2nd best\n",
    "    #\t\tif len(bests)>1:\t\n",
    "    #\t\t\tprint((bests[0])[1]-(bests[1])[1])\n",
    "\n",
    "            #bests is a list of tuples, of the form (\"street name\", ratio) \n",
    "            b0=bests[0]\n",
    "\n",
    "            r=b0[1]\n",
    "            best=b0[0]\n",
    "            ratio[i]=r\n",
    "            MATCHES_r[i]=best\n",
    "        #This is where we determine if we found an address match\n",
    "        #We consider a match if the 'best' match is significantly better than the 2nd best, AND that the best is also good (>70, semi-arbitrary cut-off).\n",
    "            #assume directions match until we find they don't\n",
    "            DIR_MATCH=True\n",
    "            RAT_MATCH=False\n",
    "            if r>cut_off:\n",
    "                if r==100: #perfect string match\n",
    "                    RAT_MATCH=True\n",
    "                else:\n",
    "                    check_list=pd.Series([addr1,best])\t\t\t\t\t\t\n",
    "                    #check to see if direction exists and matches\n",
    "                    DIR_MATCH=DirectionCheck(check_list)\n",
    "                    #check to see if the street name is a number and that if so it isn't a mismatch\n",
    "                    NUM_MATCH=NameIsNumber(check_list)\n",
    "                    if (DIR_MATCH==True) and (NUM_MATCH==True):\n",
    "                        if len(bests)>1:\n",
    "                            r1=(bests[1])[1]\n",
    "                            if (r-r1)>10: #clearly better than 2nd option\n",
    "                                RAT_MATCH=True\n",
    "\n",
    "\n",
    "                            else: #not clearly better than second option\n",
    "                                RAT_MATCH=False\n",
    "\n",
    "\n",
    "                        else: #Only one option, and score above 70\n",
    "                            RAT_MATCH=True\n",
    "                    else:\n",
    "                        RAT_MATCH =False\n",
    "            else: #Best option ratio <cutoff, not good\n",
    "                RAT_MATCH=False\n",
    "\n",
    "\n",
    "        if RAT_MATCH==True:\n",
    "                #some addresses repeat in address lists with slightly different lat/lons\n",
    "                #this is PERPLEXING. We take the mean.\n",
    "                x[i]=DF_temp.loc[DF_temp[\"street\"]==best,\"longitude\"].mean()\n",
    "                y[i]=DF_temp.loc[DF_temp[\"street\"]==best,\"latitude\"].mean()\n",
    "        else:\n",
    "                x[i]=''\n",
    "                y[i]=''\n",
    "    df[\"matches_r\"]=MATCHES_r\t\n",
    "    df[\"ratio\"]=ratio\n",
    "\n",
    "\n",
    "    df[\"x\"]=x\n",
    "    df[\"y\"]=y\n",
    "\n",
    "    #create output\n",
    "    # for testing, we don't need all the columns - just the address, and maybe the name\n",
    "#     cols = list(df)\n",
    "    # df_out = df[[cols[0],'street_no','street_name','matches_r','ratio','x','y']]\n",
    "    \n",
    "    no_matches = df['ratio'][df['ratio'] > cut_off].count()\n",
    "    print('percent matches (from sample n = 200): ', no_matches)\n",
    "    \n",
    "    output_filename = 'output-' + province_code + '.csv'\n",
    "    df.to_csv(output_filename, index=False)\n",
    "\n",
    "    t2=time.time()\n",
    "    print('time taken: ', str(round(t2-t1, 2)), '\\n')\n",
    "    \n",
    "    df_all = df_all.append(df)\n",
    "    \n",
    "\n",
    "df_all.to_csv(\"output_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-16T14:53:26.880095Z",
     "iopub.status.busy": "2022-08-16T14:53:26.878963Z",
     "iopub.status.idle": "2022-08-16T14:53:26.888025Z",
     "shell.execute_reply": "2022-08-16T14:53:26.887162Z",
     "shell.execute_reply.started": "2022-08-16T14:53:26.880056Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each province print\n",
    "# size of dataframe\n",
    "# how many were not geocoded\n",
    "# number of oda addresses\n",
    "# how many with matches found\n",
    "# how long did it take to compute\n",
    "    # if ages, then message every batch of 100\n",
    "    \n",
    "df_all.to_csv(\"output_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_exploration (odbiz)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
